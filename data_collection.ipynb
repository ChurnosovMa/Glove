{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "[[4.000e-01 4.957e+01 1.300e-01 5.240e+00 8.770e+00]\n",
      " [4.000e-02 1.490e+01 5.300e-01 5.900e-01 6.400e-01]\n",
      " [3.360e+00 5.290e+00 2.000e-02 1.386e+01 0.000e+00]\n",
      " [1.600e-01 1.000e-02 2.000e-02 1.000e-02 0.000e+00]\n",
      " [1.639e+01 1.046e+01 1.734e+01 2.651e+01 8.000e-02]]\n",
      "q\n",
      "(1283, 8, 25, 12)\n",
      "Original Data Shape: (1283, 8, 25, 12)\n",
      "Read Data Shape: (1283, 8, 25, 12)\n",
      "Read Label Shape: (1283,)\n",
      "Read Data: [[  0.     0.     0.   ...   0.     0.     0.  ]\n",
      " [ 13.47  17.47  10.47 ...   7.47  30.47  84.47]\n",
      " [103.47 151.47 164.47 ... 118.47 115.47 108.47]\n",
      " ...\n",
      " [ 93.47  93.47  94.47 ... 105.47 101.47  99.47]\n",
      " [101.47 100.47  98.47 ... 111.47 110.47 114.47]\n",
      " [111.47 110.47 112.47 ... 106.47 110.47 115.47]]\n",
      "Read Label: [4 4 4 ... 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from time import sleep\n",
    "import tkinter as tk\n",
    "from tkinter import ttk \n",
    "import serial.tools.list_ports\n",
    "import serial\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import csv\n",
    "from itertools import combinations\n",
    "import keyboard\n",
    "import h5py\n",
    "\n",
    "dim = 5\n",
    "len_of_window_to_preprocessing = 100\n",
    "len_of_trial = 8\n",
    "\n",
    "ser = serial.Serial('COM3', 9600)\n",
    "ser.flushInput()\n",
    "\n",
    "def compute_matrix_of_means(dim, len_of_window):\n",
    "    data_array_for_compute_means = np.zeros((dim, dim, len_of_window), dtype=\"int64\")\n",
    "    for step_of_full_fill in range (len_of_window):\n",
    "        data_array = np.zeros((dim, dim), dtype=\"int64\")\n",
    "        for rows in range(dim):\n",
    "            data = ser.readline().decode('utf-8').strip()\n",
    "            values = np.array([int(x) for x in data.split()])\n",
    "            match values[0]:\n",
    "                case 0: data_array[0] = values[1:]\n",
    "                case 1: data_array[1] = values[1:]\n",
    "                case 2: data_array[2] = values[1:]\n",
    "                case 3: data_array[3] = values[1:]\n",
    "                case 4: data_array[4] = values[1:]\n",
    "        data_array_for_compute_means[:, :, step_of_full_fill] = data_array\n",
    "    return np.mean(data_array_for_compute_means, axis=2) \n",
    "        \n",
    "def add_new(a, b):\n",
    "  a = np.delete(a, 0, axis=0)\n",
    "  a = np.vstack((a, b))\n",
    "  return a\n",
    "\n",
    "def pairwise_subtractions(arr):\n",
    "  valid_values = np.array(list((combinations(arr, 2))))\n",
    "  values = valid_values[:, 0] - valid_values[:, 1]\n",
    "  return values\n",
    "\n",
    "def compute_matrix_of_relationships(data):\n",
    "  new_full_matrix =  np.zeros((int(data.shape[0] * (data.shape[1] - 1) / 2), int(data.shape[0] * (data.shape[1] - 1) / 2)), dtype=\"float64\")\n",
    "  new_only_rows_matrix = np.zeros((data.shape[0], int(data.shape[0] * (data.shape[1] - 1) / 2)), dtype=\"float64\")\n",
    "  for j in range(int((data.shape[0] * (data.shape[1] - 1)) / 2)):\n",
    "      for i in range(data.shape[0]):\n",
    "          new_only_rows_matrix[i, :] = pairwise_subtractions(data[i, :])\n",
    "      new_full_matrix[:, j] = pairwise_subtractions(new_only_rows_matrix[:, j])\n",
    "  return new_full_matrix\n",
    "\n",
    "\n",
    "\n",
    "def main_loop():\n",
    "    global all_data \n",
    "    all_data = np.zeros((25, 12, len_of_trial, 1), dtype=\"float64\")\n",
    "    ser.flushInput()\n",
    "    with open(txt_file, \"w\") as txtfile:\n",
    "        labels = []\n",
    "        while True:\n",
    "            labels.append(4)\n",
    "            ser.flushInput() \n",
    "            # Check for 'q' key press to break the loop\n",
    "            if keyboard.is_pressed('q'):\n",
    "                print('q')\n",
    "                break\n",
    "            one_sample_data = np.zeros((25, 12, len_of_trial), dtype=\"float64\")\n",
    "            \n",
    "            for trial in range(len_of_trial):\n",
    "                one_matrix = np.zeros((5, 5))\n",
    "                for rows in range(dim):\n",
    "                    data = ser.readline().decode('utf-8').strip()\n",
    "                    #print(data)\n",
    "                    values = np.array([int(x) for x in data.split()])\n",
    "                    timestamp = datetime.now().strftime('%H:%M:%S.%f')\n",
    "                    txtfile.write(f\"{values},{timestamp}\\n\")\n",
    "                    if len(values) == 6:\n",
    "                        one_matrix[values[0]] = values[1:]\n",
    "                one_matrix -= matrix_of_means\n",
    "                \n",
    "                one_matrix = pairwise_subtractions(one_matrix.reshape(25)).reshape(25, 12)\n",
    "                \n",
    "                one_sample_data[:, :, trial] = one_matrix\n",
    "            all_data = np.concatenate((all_data, one_sample_data[:, :, :, np.newaxis]), axis=3)\n",
    "\n",
    "        labels = np.array(labels)\n",
    "\n",
    "    all_data = np.transpose(all_data, [3, 2, 0, 1])\n",
    "    with h5py.File(hdf5_file, 'w') as hf:\n",
    "        \n",
    "        group = hf.create_group('mydataset')\n",
    "        group.create_dataset('data', data=all_data, compression=\"gzip\") \n",
    "        group.create_dataset('label', data=labels, dtype=np.int8)  \n",
    "      \n",
    "\n",
    "              \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    txt_file = 'data_cucumber_4.txt'\n",
    "    hdf5_file = 'data_cucumber_4.h5'\n",
    "    matrix_of_means = compute_matrix_of_means(dim, len_of_window_to_preprocessing)\n",
    "    print(\"Start\")\n",
    "    print(matrix_of_means)\n",
    "    main_loop()\n",
    "    print(all_data.shape)\n",
    "    \n",
    "    #print(all_data[:, :, :, 3])  \n",
    "    with h5py.File(hdf5_file, 'r') as hf:\n",
    "        read_data = hf['mydataset']['data']\n",
    "        read_label = hf['mydataset']['label']  # [()] needed for scalar datasets\n",
    "\n",
    "        print(\"Original Data Shape:\", all_data.shape)\n",
    "\n",
    "        print(\"Read Data Shape:\", read_data.shape)\n",
    "        print(\"Read Label Shape:\", read_label.shape)\n",
    "        print(\"Read Data:\", read_data[:, :, 2, 3])\n",
    "        print(\"Read Label:\", read_label[:])\n",
    "        \n",
    "        #check if the data is identical.\n",
    "        assert np.array_equal(all_data,read_data)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
